{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR, CosineAnnealingWarmRestarts\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import transforms\n",
    "from monai.networks.nets import ResNetFeatures, ViT, resnet18\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Transformation Object\n",
    "transforms = v2.Compose([\n",
    "    #Converting images to the size that the model expects\n",
    "    v2.Resize(size=(224,224)),\n",
    "    v2.ToTensor(), #Converting to tensor\n",
    "    v2.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]) #Normalizing the data to the data that the ResNet18 was trained on\n",
    "    \n",
    "])\n",
    "\n",
    "# Create custom dataset class\n",
    "class XrayDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        xray_path = self.df.loc[idx, 'image_path']\n",
    "\n",
    "        img = Image.open(xray_path).convert(\"RGB\")\n",
    "        # img = Image.open(xray_path)\n",
    "        \n",
    "        label = int(self.df.loc[idx, 'oa_label'])\n",
    "    \n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xray_path = '/home/feg48/kl_grading_project/xray/data/cropped_images/9689922_l.jpg'\n",
    "img = Image.open(xray_path).convert(\"RGB\")\n",
    "img2 = transforms(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63346/3135094797.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_weights = torch.load(\"../resnet_18_23dataset.pth\")\n"
     ]
    }
   ],
   "source": [
    "# model = MonaiResNet183DWrapper()\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "pretrained_weights = torch.load(\"../resnet_18_23dataset.pth\")\n",
    "model.load_state_dict({k: v for k, v in pretrained_weights.items() if \"fc\" not in k}, strict=False)\n",
    "model.fc = torch.nn.Linear(in_features=512, out_features=1)\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "model = model.cuda()\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-04)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feg48/myenv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/feg48/myenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_63346/2818643565.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_weights = torch.load(\"../resnet_18_23dataset.pth\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6537550299860245\n",
      "Training Accuracy: 0.6179245283018868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6408106088638306\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5855380363304522\n",
      "Training Accuracy: 0.6811670160726765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6547868847846985\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4993752064651617\n",
      "Training Accuracy: 0.7416142557651991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6652690172195435\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3493220183436431\n",
      "Training Accuracy: 0.8385744234800838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6652690172195435\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.21602941529211386\n",
      "Training Accuracy: 0.9135220125786163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6638714075088501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Best Model Final Validation Accuracy: 0.6652690172195435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "cv_best_models = []\n",
    "cv_best_acc = []\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "for fold in range(1, 2):\n",
    "    xray_train_df = pd.read_csv(f\"data/xray_train_cv{fold}.csv\")\n",
    "    xray_valid_df = pd.read_csv(f\"data/xray_val_cv{fold}.csv\")\n",
    "    xray_train_dataset = XrayDataset(xray_train_df,  transforms=transforms)\n",
    "    xray_train_dataloader = DataLoader(xray_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    xray_val_dataset = XrayDataset(xray_valid_df, transforms=transforms)\n",
    "    xray_val_dataloader = DataLoader(xray_val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    model = torchvision.models.resnet18(pretrained=True)\n",
    "    pretrained_weights = torch.load(\"../resnet_18_23dataset.pth\")\n",
    "    model.load_state_dict({k: v for k, v in pretrained_weights.items() if \"fc\" not in k}, strict=False)\n",
    "    model.fc = torch.nn.Linear(in_features=512, out_features=1)\n",
    "    model = nn.DataParallel(model)\n",
    "    model = model.cuda()\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-04)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n",
    "    \n",
    "    best_val_acc = 0.\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        losses = []\n",
    "        correct = 0\n",
    "\n",
    "        for img, label in tqdm(xray_train_dataloader, leave=False):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            out = model(img.cuda()).squeeze(1)\n",
    "            loss = loss_fn(out, label.float().cuda())\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "    \n",
    "            correct += torch.sum((label.cuda() == (out > 0.5))).item()\n",
    "            \n",
    "            optimizer.step()\n",
    "        print(f\"Training Loss: {np.mean(losses)}\")\n",
    "        print(f\"Training Accuracy: {correct/(len(xray_train_df))}\")\n",
    "    \n",
    "        correct = 0\n",
    "        # losses = 0\n",
    "        for img, label in tqdm(xray_val_dataloader, leave=False):\n",
    "            out = model(img.cuda()).squeeze(1)\n",
    "    \n",
    "            preds = (out > 0.5).float()\n",
    "            loss = loss_fn(preds, label.float().cuda())\n",
    "    \n",
    "            # losses += loss.item() * img.size(0)\n",
    "            correct += torch.sum(preds == label.cuda())\n",
    "    \n",
    "    \n",
    "        final_acc = correct/len(xray_valid_df)\n",
    "        print(f\"Validation Accuracy: {final_acc}\")\n",
    "    \n",
    "        if final_acc > best_val_acc:\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_val_acc = final_acc\n",
    "    \n",
    "        scheduler.step()\n",
    "    \n",
    "    losses = 0\n",
    "    correct = 0\n",
    "    for img, label in tqdm(xray_val_dataloader, leave=False):\n",
    "        out = best_model(img.cuda()).squeeze(1)\n",
    "    \n",
    "        preds = (out > 0.5).float()\n",
    "        loss = loss_fn(preds, label.float().cuda())\n",
    "    \n",
    "        losses += loss.item() * img.size(0)\n",
    "        correct += torch.sum(preds == label.cuda())\n",
    "    \n",
    "    \n",
    "    final_acc = correct/len(xray_valid_df)\n",
    "    print(f\"Fold {fold} Best Model Final Validation Accuracy: {final_acc}\")\n",
    "\n",
    "    cv_best_models.append(copy.deepcopy(best_model))\n",
    "    cv_best_acc.append(final_acc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc = np.argmax([item.item() for item in cv_best_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.6653, device='cuda:0')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = cv_best_models[max_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:04<00:00, 12.15it/s]\n"
     ]
    }
   ],
   "source": [
    "xray_test_df= pd.read_csv(\"data/xray_test.csv\")\n",
    "xray_test_dataset = XrayDataset(xray_test_df, transforms=transforms)\n",
    "xray_test_dataloader = DataLoader(xray_test_dataset, batch_size=batch_size)\n",
    "\n",
    "labels = []\n",
    "preds = []\n",
    "for img, label in tqdm(xray_test_dataloader):\n",
    "    out = best_model(img.cuda()).squeeze(1)\n",
    "    preds.extend((out > 0.5).int().cpu().numpy())\n",
    "    labels.extend(label.cpu().numpy())\n",
    "\n",
    "    # correct += torch.sum(preds == label.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n",
      "Precision: 0.69\n",
      "Recall: 0.47\n",
      "F1 Score: 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "precision = precision_score(labels, preds)\n",
    "recall = recall_score(labels, preds)\n",
    "f1 = f1_score(labels, preds)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6898, device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/len(xray_test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
